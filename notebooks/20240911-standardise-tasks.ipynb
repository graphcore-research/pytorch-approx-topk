{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import typing\n",
    "\n",
    "import theoretical_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing (standardised) data frames\n",
    "\n",
    "Each task's experimentor will have some way that they've saved the data. The DataFrame class below is a base class that each task can inherit from, and standardise the way that the data is stored. It also marries up the experimentor's recall investigations with the speed measuring results, which are computed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrame:\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_dataframe(file: str) -> pd.DataFrame:\n",
    "        \"\"\"Helper method to load file into data frame\"\"\"\n",
    "        match file.split(\".\")[-1]:\n",
    "            case \"csv\":\n",
    "                return pd.read_csv(file)\n",
    "            case \"json\":\n",
    "                return pd.read_json(file)\n",
    "            case \"jsonl\":\n",
    "                return pd.read_json(file, lines=True)\n",
    "            case _:\n",
    "                raise ValueError(\"Don't know how to open filetype\")\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _save_dataframe(filename: str, df: pd.DataFrame) -> None:\n",
    "        \"\"\"Helper method to save data frame into file\"\"\"\n",
    "        with open(filename, \"w\") as file:\n",
    "            match filename.split(\".\")[-1]:\n",
    "                case \"csv\":\n",
    "                    file.write(df.to_csv())\n",
    "                case \"json\":\n",
    "                    file.write(df.to_json(orient=\"records\"))\n",
    "                case \"jsonl\":\n",
    "                    file.write(df.to_json(orient=\"records\", lines=True))\n",
    "                case _:\n",
    "                    raise ValueError(\"Invalid filetype\")\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_dataframe(\n",
    "        cls: typing.Self, \n",
    "        files: typing.Union[str, list[str]], \n",
    "        feature_prefix: str, \n",
    "        features: list[str],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Helper method to build a preprocessed data frame\"\"\"    \n",
    "        df = pd.DataFrame()\n",
    "        if isinstance(files, str):\n",
    "            data = cls._load_dataframe(files)\n",
    "        else:\n",
    "            data = pd.concat([*map(cls._load_dataframe, files)])\n",
    "        print(features)\n",
    "        for feature in tqdm.tqdm(features, desc=f\"{feature_prefix} features\"):\n",
    "            function = getattr(cls, f\"{feature_prefix}_{feature}\")\n",
    "            df.loc[:, feature] = data.apply(function, axis=1)\n",
    "        return df\n",
    "\n",
    "    def __new__(\n",
    "        cls: typing.Self, \n",
    "        recall_files: typing.Union[str, list[str]] = None,\n",
    "        recall_features: list[str] = [],\n",
    "        speed_files: typing.Union[str, list[str]]  = None,\n",
    "        speed_features: list[str] = [],\n",
    "        save_file: str = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Instantiate a generic preprocessed data frame\"\"\"\n",
    "        recall_features += [\"k\", \"b\", \"k_mult\", \"k_b\", \"interleaved\", \"recall\", \"error\"]\n",
    "        if recall_files:\n",
    "            print(recall_features)\n",
    "            recall_df = cls._build_dataframe(cls, recall_files, \"recall\", recall_features)\n",
    "        if speed_files:\n",
    "            speed_features += [\"n\", \"n_over_k\", \"batch_size\", \"k\", \"b\", \"k_mult\", \"k_b\", \"interleaved\"]\n",
    "            speed_features += [\"method\", \"compile\", \"duration_mean\", \"duration_stdv\"]\n",
    "            speed_features += [\"cost_basic\", \"cost_serial\", \"cost_parallel\", \"dtype\", \"n_inner\"]\n",
    "            speed_df = cls._build_dataframe(cls, speed_files, \"speed\", speed_features)\n",
    "            if recall_files:\n",
    "                merged_df = pd.merge(recall_df, speed_df)\n",
    "            else:\n",
    "                merged_df = speed_df\n",
    "            if save_file:\n",
    "                cls._save_dataframe(save_file, merged_df)\n",
    "            return merged_df\n",
    "        return recall_df, \n",
    "            \n",
    "\n",
    "    def speed_n(row):\n",
    "        return row[\"topk_size\"]\n",
    "\n",
    "    def speed_n_over_k(row):\n",
    "        return round(row[\"topk_size\"] / row[\"k\"], 3)\n",
    "\n",
    "    def speed_batch_size(row):\n",
    "        return row[\"batch_size\"]\n",
    "\n",
    "    def speed_k(row):\n",
    "        return row[\"k\"]\n",
    "    \n",
    "    def speed_b(row):\n",
    "        return (row[\"k\"] // row[\"j\"]) * row[\"k_mult\"]\n",
    "\n",
    "    def speed_k_mult(row):\n",
    "        return row[\"k_mult\"]\n",
    "    \n",
    "    def speed_k_b(row):\n",
    "        return row[\"j\"]\n",
    "\n",
    "    def speed_interleaved(row):\n",
    "        return row[\"args\"].get(\"interleaved\", True)\n",
    "    \n",
    "    def speed_method(row):\n",
    "        return row[\"method\"]\n",
    "\n",
    "    def speed_compile(row):\n",
    "        return row[\"compile\"]\n",
    "\n",
    "    def speed_duration_mean(row):\n",
    "        return np.mean(row[\"duration\"])\n",
    "\n",
    "    def speed_duration_stdv(row):\n",
    "        return np.std(row[\"duration\"])\n",
    "\n",
    "    def speed_cost_basic(row):\n",
    "        return theoretical_models.cost_basic.approx_topk(\n",
    "            k=row[\"k\"], \n",
    "            n=row[\"topk_size\"],\n",
    "            m=row[\"batch_size\"],\n",
    "            b=(row[\"k\"] // row[\"j\"]) * row[\"k_mult\"],\n",
    "            k_b=row[\"j\"],\n",
    "        )\n",
    "\n",
    "    def speed_cost_serial(row):\n",
    "        return theoretical_models.cost_serial.approx_topk(\n",
    "            k=row[\"k\"], \n",
    "            n=row[\"topk_size\"],\n",
    "            m=row[\"batch_size\"],\n",
    "            b=(row[\"k\"] // row[\"j\"]) * row[\"k_mult\"],\n",
    "            k_b=row[\"j\"],\n",
    "        )\n",
    "\n",
    "    def speed_cost_parallel(row):\n",
    "        return theoretical_models.cost_parallel.approx_topk(\n",
    "            k=row[\"k\"], \n",
    "            n=row[\"topk_size\"],\n",
    "            m=row[\"batch_size\"],\n",
    "            b=(row[\"k\"] // row[\"j\"]) * row[\"k_mult\"],\n",
    "            k_b=row[\"j\"],\n",
    "        )\n",
    "\n",
    "    def speed_dtype(row):\n",
    "        return row[\"dtype\"]\n",
    "\n",
    "    def speed_n_inner(row):\n",
    "        return row[\"n_inner\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task-specific data frame classes below describe the mapping from each experimentor's saved data to a standard approach. \n",
    "\n",
    "_Note: as benchmarking has all been run by Alberto, the speed data is the same across all tasks, and therefore is included in the parent DataFrame class._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabDataFrame(DataFrame):\n",
    "\n",
    "    def recall_k(row):\n",
    "        return row[\"k\"]\n",
    "    \n",
    "    def recall_b(row):\n",
    "        return row[\"num_buckets\"] * row[\"k_mult\"]\n",
    "\n",
    "    def recall_k_mult(row):\n",
    "        return row[\"k_mult\"]\n",
    "    \n",
    "    def recall_k_b(row):\n",
    "        return row[\"k_per_bucket\"]\n",
    "\n",
    "    def recall_interleaved(row):\n",
    "        return row[\"interleaved\"]\n",
    "\n",
    "    def recall_recall(row):\n",
    "        k = row[\"k\"]\n",
    "        return row[f\"recall_k{k}\"]\n",
    "\n",
    "    def recall_error(row):\n",
    "        k = row[\"k\"]\n",
    "        return 1 - row[f\"recall_k{k}\"]\n",
    "\n",
    "\n",
    "\n",
    "class GraphDataFrame(DataFrame):\n",
    "\n",
    "    def recall_k(row):\n",
    "        return row[\"K\"]\n",
    "    \n",
    "    def recall_b(row):\n",
    "        return row[\"n_buckets\"]\n",
    "\n",
    "    def recall_k_mult(row):\n",
    "        return row[\"k_mult\"]\n",
    "    \n",
    "    def recall_k_b(row):\n",
    "        return row[\"J\"]\n",
    "\n",
    "    def recall_interleaved(_):\n",
    "        return True\n",
    "\n",
    "    def recall_recall(row):\n",
    "        return row[f\"recall_interleaved\"]\n",
    "\n",
    "    def recall_error(row):\n",
    "        return 1 - row[f\"recall_interleaved\"]\n",
    "\n",
    "\n",
    "class SparQDataFrame(DataFrame):\n",
    "    \n",
    "    def recall_k(row):\n",
    "        return row[\"k\"]\n",
    "    \n",
    "    def recall_b(row):\n",
    "        return (row[\"k\"] // row[\"topk_k_per_bucket\"]) * row[\"topk_k_mult\"]\n",
    "\n",
    "    def recall_k_mult(row):\n",
    "        return row[\"topk_k_mult\"]\n",
    "    \n",
    "    def recall_k_b(row):\n",
    "        return row[\"topk_k_per_bucket\"]\n",
    "\n",
    "    def recall_interleaved(row):\n",
    "        return bool(row[\"topk_interleaved\"])\n",
    "\n",
    "    def recall_recall(_):\n",
    "        return None\n",
    "\n",
    "    def recall_error(_):\n",
    "        return None\n",
    "\n",
    "    def recall_score(row):\n",
    "        return row[\"score\"]\n",
    "\n",
    "    def recall_n(row):\n",
    "        return {\"squad\": 1409, \"repetition\": 1659}[row[\"task_name\"]]\n",
    "\n",
    "    def recall_exact_topk(row):\n",
    "        return not row[\"bucket_topk\"]\n",
    "\n",
    "\n",
    "\n",
    "class SynthDataFrame(DataFrame):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # exact_graph_df = GraphDataFrame(\n",
    "# #     speed_files=\"../data/measure_speed_kgc_new.jsonl\",\n",
    "# # )\n",
    "# # exact_graph_df = exact_graph_df[exact_graph_df.method == \"approx_topk.torch_default.topk\"]\n",
    "# # exact_graph_df = exact_graph_df[exact_graph_df.compile.isin([None])]\n",
    "# # exact_graph_df.loc[:, \"recall\"] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# graph_df = GraphDataFrame(\n",
    "#     save_file=\"../data/graph-data-merged.jsonl\",\n",
    "#     recall_files=\"../data/graph-recall-data.csv\", \n",
    "#     speed_files=\"../data/measure_speed_kgc_multi2.jsonl\",\n",
    "# )\n",
    "\n",
    "# # graph_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# exact_graph_df = exact_graph_df[exact_graph_df.method == \"approx_topk.torch_default.topk\"]\n",
    "# exact_graph_df = exact_graph_df[exact_graph_df.compile.isin([None])]\n",
    "# exact_graph_df.loc[:, \"recall\"] = 1\n",
    "\n",
    "# # GraphDataFrame._save_dataframe(\"../data/graph-data-exact-merged.jsonl\", exact_graph_df)\n",
    "# i = graph_df[graph_df.k_b == 4]\n",
    "# i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_df = VocabDataFrame(\n",
    "    save_file=\"../data/vocab-data-merged.jsonl\",\n",
    "    recall_files=\"../data/vocab-recall-data.csv\", \n",
    "    speed_files=\"../data/measure_speed_vocab_multi2.jsonl\",\n",
    ")\n",
    "vocab_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b: 100%|██████████| 16/16 [03:07<00:00, 11.72s/it]\n",
      "b: 100%|██████████| 16/16 [03:06<00:00, 11.69s/it]17s/it]\n",
      "b: 100%|██████████| 16/16 [03:04<00:00, 11.52s/it]88s/it]\n",
      "b: 100%|██████████| 16/16 [03:04<00:00, 11.54s/it]57s/it]\n",
      "b: 100%|██████████| 16/16 [03:04<00:00, 11.56s/it]04s/it]\n",
      "BatchSize: 100%|██████████| 5/5 [15:31<00:00, 186.34s/it]\n"
     ]
    }
   ],
   "source": [
    "_dfs = []\n",
    "for batch_size in tqdm.tqdm([*set(vocab_df.batch_size)], desc=\"BatchSize\"):\n",
    "    for b in tqdm.tqdm([*set(vocab_df.b)], desc=\"b\"):\n",
    "        for k_b in [*set(vocab_df.k_b)]:\n",
    "            for k in [*set(vocab_df.k)]:\n",
    "                _df = vocab_df[vocab_df.batch_size == batch_size]\n",
    "                _df = _df[_df.b == b]\n",
    "                _df = _df[_df.k_b == k_b]\n",
    "                _df = _df[_df.k == k]\n",
    "                if len(_df):\n",
    "                    new_df = _df.iloc[:1]\n",
    "                    new_df.loc[:, \"recall\"] = _df.recall.mean(),\n",
    "                    new_df.loc[:, \"error\"] = _df.error.mean(),\n",
    "                    _dfs += [new_df]\n",
    "\n",
    "big_df = pd.concat(_dfs)\n",
    "VocabDataFrame._save_dataframe(\"../data/vocab-data-merged-compressed.jsonl\", big_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['n', 'n_over_k', 'batch_size', 'k', 'b', 'k_mult', 'k_b', 'interleaved', 'method', 'compile', 'duration_mean', 'duration_stdv', 'cost_basic', 'cost_serial', 'cost_parallel', 'dtype', 'n_inner', 'n', 'n_over_k', 'batch_size', 'k', 'b', 'k_mult', 'k_b', 'interleaved', 'method', 'compile', 'duration_mean', 'duration_stdv', 'cost_basic', 'cost_serial', 'cost_parallel', 'dtype', 'n_inner', 'n', 'n_over_k', 'batch_size', 'k', 'b', 'k_mult', 'k_b', 'interleaved', 'method', 'compile', 'duration_mean', 'duration_stdv', 'cost_basic', 'cost_serial', 'cost_parallel', 'dtype', 'n_inner', 'n', 'n_over_k', 'batch_size', 'k', 'b', 'k_mult', 'k_b', 'interleaved', 'method', 'compile', 'duration_mean', 'duration_stdv', 'cost_basic', 'cost_serial', 'cost_parallel', 'dtype', 'n_inner']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "speed features: 100%|██████████| 68/68 [00:02<00:00, 24.05it/s]\n"
     ]
    }
   ],
   "source": [
    "exact_vocab_df = VocabDataFrame(\n",
    "    speed_files=\"../data/measure_speed_vocab_new.jsonl\",\n",
    ")\n",
    "exact_vocab_df = exact_vocab_df[exact_vocab_df.method == \"approx_topk.torch_default.topk\"]\n",
    "exact_vocab_df = exact_vocab_df[exact_vocab_df.compile.isin([None])]\n",
    "exact_vocab_df.loc[:, \"recall\"] = 1\n",
    "\n",
    "VocabDataFrame._save_dataframe(\"../data/vocab-data-exact-merged.jsonl\", exact_vocab_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SparQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "recall features: 100%|██████████| 10/10 [00:00<00:00, 1032.88it/s]\n",
      "speed features: 100%|██████████| 1054/1054 [00:00<00:00, 1396.53it/s]\n",
      "recall features: 100%|██████████| 10/10 [00:00<00:00, 1683.85it/s]\n",
      "speed features: 100%|██████████| 1071/1071 [00:00<00:00, 1414.33it/s]\n"
     ]
    }
   ],
   "source": [
    "repetition_df = SparQDataFrame(\n",
    "    recall_files=\"../data/sparq_v1.jsonl\",\n",
    "    recall_features=[\"score\", \"n\", \"exact_topk\"],\n",
    "    speed_files=\"../data/measure_speed_sparq_multi2.jsonl\",\n",
    ")\n",
    "repetition_df = repetition_df[repetition_df.n == 1659]\n",
    "\n",
    "\n",
    "squad_df = SparQDataFrame(\n",
    "    recall_files=\"../data/sparq_v2.jsonl\",\n",
    "    recall_features=[\"score\", \"n\", \"exact_topk\"],\n",
    "    speed_files=\"../data/measure_speed_sparq_multi2.jsonl\",\n",
    ")\n",
    "squad_df = squad_df[squad_df.n == 1409]\n",
    "\n",
    "merged_df = pd.concat([squad_df, repetition_df])\n",
    "\n",
    "\n",
    "SparQDataFrame._save_dataframe(\"../data/sparq-data-merged.jsonl\", merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "recall features: 100%|██████████| 10/10 [00:00<00:00, 1034.51it/s]\n",
      "speed features: 100%|██████████| 1122/1122 [00:01<00:00, 997.15it/s] \n",
      "recall features: 100%|██████████| 10/10 [00:00<00:00, 1553.10it/s]\n",
      "speed features: 100%|██████████| 1139/1139 [00:01<00:00, 984.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>n</th>\n",
       "      <th>exact_topk</th>\n",
       "      <th>k</th>\n",
       "      <th>b</th>\n",
       "      <th>k_mult</th>\n",
       "      <th>k_b</th>\n",
       "      <th>interleaved</th>\n",
       "      <th>recall</th>\n",
       "      <th>error</th>\n",
       "      <th>...</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>method</th>\n",
       "      <th>compile</th>\n",
       "      <th>duration_mean</th>\n",
       "      <th>duration_stdv</th>\n",
       "      <th>cost_basic</th>\n",
       "      <th>cost_serial</th>\n",
       "      <th>cost_parallel</th>\n",
       "      <th>dtype</th>\n",
       "      <th>n_inner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>211.0920</td>\n",
       "      <td>1659</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>approx_topk.torch_default.topk</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000486</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>12583.452789</td>\n",
       "      <td>77615.307462</td>\n",
       "      <td>399.950603</td>\n",
       "      <td>float16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211.0920</td>\n",
       "      <td>1659</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>approx_topk.torch_default.topk</td>\n",
       "      <td>default</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>12583.452789</td>\n",
       "      <td>77615.307462</td>\n",
       "      <td>399.950603</td>\n",
       "      <td>float16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8105</td>\n",
       "      <td>1409</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>approx_topk.torch_default.topk</td>\n",
       "      <td>None</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10687.212164</td>\n",
       "      <td>64591.129432</td>\n",
       "      <td>386.209569</td>\n",
       "      <td>float16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.8105</td>\n",
       "      <td>1409</td>\n",
       "      <td>True</td>\n",
       "      <td>96</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>True</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>approx_topk.torch_default.topk</td>\n",
       "      <td>default</td>\n",
       "      <td>0.000521</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>10687.212164</td>\n",
       "      <td>64591.129432</td>\n",
       "      <td>386.209569</td>\n",
       "      <td>float16</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      score     n  exact_topk   k    b  k_mult   k_b  interleaved recall  \\\n",
       "0  211.0920  1659        True  96  1.0     1.0  96.0         True   None   \n",
       "1  211.0920  1659        True  96  1.0     1.0  96.0         True   None   \n",
       "0    0.8105  1409        True  96  1.0     1.0  96.0         True   None   \n",
       "1    0.8105  1409        True  96  1.0     1.0  96.0         True   None   \n",
       "\n",
       "  error  ...  batch_size                          method  compile  \\\n",
       "0  None  ...           1  approx_topk.torch_default.topk     None   \n",
       "1  None  ...           1  approx_topk.torch_default.topk  default   \n",
       "0  None  ...           1  approx_topk.torch_default.topk     None   \n",
       "1  None  ...           1  approx_topk.torch_default.topk  default   \n",
       "\n",
       "  duration_mean  duration_stdv    cost_basic   cost_serial  cost_parallel  \\\n",
       "0      0.000486       0.000007  12583.452789  77615.307462     399.950603   \n",
       "1      0.000538       0.000005  12583.452789  77615.307462     399.950603   \n",
       "0      0.000473       0.000004  10687.212164  64591.129432     386.209569   \n",
       "1      0.000521       0.000004  10687.212164  64591.129432     386.209569   \n",
       "\n",
       "     dtype n_inner  \n",
       "0  float16      32  \n",
       "1  float16      32  \n",
       "0  float16      32  \n",
       "1  float16      32  \n",
       "\n",
       "[4 rows x 21 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for n, file in zip([1659, 1409], [\"../data/sparq_v1.jsonl\", \"../data/sparq_v2.jsonl\"]):\n",
    "\n",
    "    # luka_df = pd.read_json(file, lines=True)\n",
    "    # luka_df = luka_df[(luka_df.bucket_topk == False) & (luka_df.task_name == task_name)]\n",
    "    luka_df = SparQDataFrame(recall_files=file, recall_features=[\"score\", \"n\", \"exact_topk\"])[0]\n",
    "    luka_df = luka_df[luka_df.n == n]\n",
    "    luka_df = luka_df[luka_df.exact_topk == True]\n",
    "    luka_df.loc[:, \"b\"] = 1\n",
    "    luka_df.loc[:, \"k_mult\"] = 1\n",
    "    luka_df.loc[:, \"k_b\"] = 96\n",
    "    \n",
    "    alberto_df = SparQDataFrame(speed_files=\"../data/measure_speed_sparq.jsonl\")\n",
    "    alberto_df = alberto_df[alberto_df.b == 1]\n",
    "    alberto_df = alberto_df[alberto_df.n == n]\n",
    "\n",
    "    \n",
    "    \n",
    "    dfs += [pd.merge(luka_df, alberto_df)]\n",
    "\n",
    "all_df = pd.concat(dfs)\n",
    "\n",
    "SparQDataFrame._save_dataframe(\"../data/sparq-data-exact-merged.jsonl\", all_df)\n",
    "\n",
    "all_df\n",
    "\n",
    "# alberto_df = pd.read_json(\"../data/measure_speed_sparq.jsonl\", lines=True)\n",
    "# alberto_df = alberto_df[alberto_df.topk_size == 1659]\n",
    "# print(alberto_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "recall features: 100%|██████████| 10/10 [00:00<00:00, 1032.75it/s]\n",
      "speed features: 100%|██████████| 782/782 [00:00<00:00, 998.64it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# repetition_df = SparQDataFrame(\n",
    "#     recall_files=\"../data/sparq_v1.jsonl\",\n",
    "#     recall_features=[\"score\", \"n\", \"bucket_topk\"],\n",
    "#     speed_files=\"../data/measure_speed_sparq.jsonl\",\n",
    "# )\n",
    "# repetition_df = repetition_df[repetition_df.n == 1659]\n",
    "\n",
    "\n",
    "# squad_df = SparQDataFrame(\n",
    "#     recall_files=\"../data/sparq_v2.jsonl\",\n",
    "#     recall_features=[\"score\", \"n\", \"bucket_topk\"],\n",
    "#     speed_files=\"../data/measure_speed_sparq.jsonl\",\n",
    "# )\n",
    "# squad_df = squad_df[squad_df.n == 1409]\n",
    "\n",
    "# print(repetition_df)\n",
    "print([*set(repetition_df.bucket_topk)])\n",
    "\n",
    "merged_df = pd.concat([squad_df, repetition_df])\n",
    "\n",
    "merged_df = merged_df[merged_df.bucket_topk == False]\n",
    "\n",
    "# SparQDataFrame._save_dataframe(\"../data/sparq-data-merged-exact.jsonl\", merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "speed features: 100%|██████████| 119/119 [00:02<00:00, 48.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def synth_recall(row):\n",
    "    try:\n",
    "        value = theoretical_models.recall.simulation(\n",
    "            k=row[\"k\"],\n",
    "            n=row[\"n\"],\n",
    "            m=row[\"batch_size\"],\n",
    "            b=row[\"b\"],\n",
    "            k_b=row[\"k_b\"],\n",
    "            reps=5,\n",
    "        )[0]\n",
    "        print(\"Wow\")\n",
    "        return value\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "\n",
    "filename = \"../data/synth-data-merged-v2.jsonl\"\n",
    "\n",
    "synth_df = SynthDataFrame(\n",
    "    save_file=filename,\n",
    "    speed_files=[\n",
    "        # \"../data/measure_speed_approx_finer.jsonl\",\n",
    "        \"../data/measure_speed_exact_finer.jsonl\",\n",
    "        \"../data/measure_speed_approx_finer_multi2.jsonl\",\n",
    "        \"../data/measure_speed_approx_finer_max_k.jsonl\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(len(synth_df))\n",
    "\n",
    "# synth_df.loc[:, \"recall_simulation\"] = synth_df.apply(synth_recall, axis=1)\n",
    "\n",
    "# synth_df\n",
    "\n",
    "# with open(filename, \"w\") as file:\n",
    "#     match filename.split(\".\")[-1]:\n",
    "#         case \"csv\":\n",
    "#             file.write(synth_df.to_csv())\n",
    "#         case \"json\":\n",
    "#             file.write(synth_df.to_json(orient=\"records\"))\n",
    "#         case \"jsonl\":\n",
    "#             file.write(synth_df.to_json(orient=\"records\", lines=True))\n",
    "\n",
    "\n",
    "\n",
    "# df = pd.read_json(\"../data/synth-data-merged-v2.jsonl\", lines=True)\n",
    "# df = pd.read_json(\"../data/measure_speed_approx_finer.jsonl\", lines=True)\n",
    "# df = df[df.method == \"approx_topk.bucket_argmax.topk_torch\"]\n",
    "# df = df[df.batch_size == 256]\n",
    "# df = df[df.k == 256]\n",
    "\n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3031c7d28276693763c906ac6cd6e99ad46c4d38a0966ad2671ff0ba747c6d17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
