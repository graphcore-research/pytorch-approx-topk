{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import typing\n",
    "\n",
    "import theoretical_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing (standardised) data frames\n",
    "\n",
    "Each task's experimentor will have some way that they've saved the data. The DataFrame class below is a base class that each task can inherit from, and standardise the way that the data is stored. It also marries up the experimentor's recall investigations with the speed measuring results, which are computed separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrame:\n",
    "\n",
    "    @staticmethod\n",
    "    def _load_dataframe(file: str) -> pd.DataFrame:\n",
    "        \"\"\"Helper method to load file into data frame\"\"\"\n",
    "        if file.split(\".\")[-1] == \"csv\":\n",
    "            return pd.read_csv(file)\n",
    "        elif file.split(\".\")[-1] == \"json\":\n",
    "            return pd.read_json(file)\n",
    "        elif file.split(\".\")[-1] == \"jsonl\":\n",
    "            return pd.read_json(file, lines=True)\n",
    "\n",
    "    @staticmethod\n",
    "    def _build_dataframe(\n",
    "        cls: typing.Self, \n",
    "        file: str, \n",
    "        feature_prefix: str, \n",
    "        features: list[str],\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Helper method to build a preprocessed data frame\"\"\"\n",
    "        df, data = pd.DataFrame(), cls._load_dataframe(file)\n",
    "        for feature in tqdm.tqdm(features, desc=f\"{feature_prefix} features\"):\n",
    "            function = getattr(cls, f\"{feature_prefix}_{feature}\")\n",
    "            df.loc[:, feature] = data.apply(function, axis=1)\n",
    "        return df\n",
    "\n",
    "    def __new__(\n",
    "        cls: typing.Self, \n",
    "        recall_file: str,\n",
    "        speed_file: str = None,\n",
    "        save_file: str = None,\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Instantiate a generic preprocessed data frame\"\"\"\n",
    "        features = [\"k\", \"b\", \"k_mult\", \"k_b\", \"interleaved\", \"metric\"]\n",
    "        recall_df = cls._build_dataframe(cls, recall_file, \"recall\", features)\n",
    "        if speed_file:\n",
    "            features = [\"n\", \"batch_size\", \"k\", \"b\", \"k_mult\", \"k_b\", \"interleaved\"]\n",
    "            features += [\"method\", \"duration_mean\", \"duration_stdv\"]\n",
    "            features += [\"cost_basic\", \"cost_serial\", \"cost_parallel\"]\n",
    "            speed_df = cls._build_dataframe(cls, speed_file, \"speed\", features)\n",
    "            merged_df = pd.merge(recall_df, speed_df)\n",
    "            if save_file:\n",
    "                with open(save_file, \"w\") as file:\n",
    "                    file.write(merged_df.to_json(lines=True, orient=\"records\"))\n",
    "            return merged_df\n",
    "        return recall_df\n",
    "            \n",
    "\n",
    "    def speed_n(row):\n",
    "        return row[\"topk_size\"]\n",
    "\n",
    "    def speed_batch_size(row):\n",
    "        return row[\"batch_size\"]\n",
    "\n",
    "    def speed_k(row):\n",
    "        return row[\"k\"]\n",
    "    \n",
    "    def speed_b(row):\n",
    "        return (row[\"k\"] // row[\"j\"]) * row[\"k_mult\"]\n",
    "\n",
    "    def speed_k_mult(row):\n",
    "        return row[\"k_mult\"]\n",
    "    \n",
    "    def speed_k_b(row):\n",
    "        return row[\"j\"]\n",
    "\n",
    "    def speed_interleaved(row):\n",
    "        return row[\"args\"].get(\"interleaved\", True)\n",
    "    \n",
    "    def speed_method(row):\n",
    "        return row[\"method\"]\n",
    "\n",
    "    def speed_duration_mean(row):\n",
    "        return np.mean(row[\"duration\"])\n",
    "\n",
    "    def speed_duration_stdv(row):\n",
    "        return np.std(row[\"duration\"])\n",
    "\n",
    "    def speed_cost_basic(row):\n",
    "        return theoretical_models.cost_basic.approx_topk(\n",
    "            k=row[\"k\"], \n",
    "            n=row[\"topk_size\"],\n",
    "            m=row[\"batch_size\"],\n",
    "            b=(row[\"k\"] // row[\"j\"]) * row[\"k_mult\"],\n",
    "            k_b=row[\"j\"],\n",
    "        )\n",
    "\n",
    "    def speed_cost_serial(row):\n",
    "        return theoretical_models.cost_serial.approx_topk(\n",
    "            k=row[\"k\"], \n",
    "            n=row[\"topk_size\"],\n",
    "            m=row[\"batch_size\"],\n",
    "            b=(row[\"k\"] // row[\"j\"]) * row[\"k_mult\"],\n",
    "            k_b=row[\"j\"],\n",
    "        )\n",
    "\n",
    "    def speed_cost_parallel(row):\n",
    "        return theoretical_models.cost_parallel.approx_topk(\n",
    "            k=row[\"k\"], \n",
    "            n=row[\"topk_size\"],\n",
    "            m=row[\"batch_size\"],\n",
    "            b=(row[\"k\"] // row[\"j\"]) * row[\"k_mult\"],\n",
    "            k_b=row[\"j\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task-specific data frame classes below describe the mapping from each experimentor's saved data to a standard approach. \n",
    "\n",
    "_Note: as benchmarking has all been run by Alberto, the speed data is the same across all tasks, and therefore is included in the parent DataFrame class._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabDataFrame(DataFrame):\n",
    "\n",
    "    def recall_k(row):\n",
    "        return row[\"k\"]\n",
    "    \n",
    "    def recall_b(row):\n",
    "        return row[\"num_buckets\"] * row[\"k_mult\"]\n",
    "\n",
    "    def recall_k_mult(row):\n",
    "        return row[\"k_mult\"]\n",
    "    \n",
    "    def recall_k_b(row):\n",
    "        return row[\"k_per_bucket\"]\n",
    "\n",
    "    def recall_interleaved(row):\n",
    "        return row[\"interleaved\"]\n",
    "\n",
    "    def recall_metric(row):\n",
    "        k = row[\"k\"]\n",
    "        return row[f\"recall_k{k}\"]\n",
    "\n",
    "\n",
    "\n",
    "class GraphDataFrame(DataFrame):\n",
    "\n",
    "    def recall_k(row):\n",
    "        return row[\"K\"]\n",
    "    \n",
    "    def recall_b(row):\n",
    "        return row[\"n_buckets\"]\n",
    "\n",
    "    def recall_k_mult(row):\n",
    "        return row[\"k_mult\"]\n",
    "    \n",
    "    def recall_k_b(row):\n",
    "        return row[\"J\"]\n",
    "\n",
    "    def recall_interleaved(_):\n",
    "        return True\n",
    "\n",
    "    def recall_metric(row):\n",
    "        return row[f\"recall_interleaved\"]\n",
    "\n",
    "\n",
    "class SparQDataFrame(DataFrame):\n",
    "    pass\n",
    "\n",
    "\n",
    "class SynthDataFrame(DataFrame):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "recall features: 100%|██████████| 6/6 [00:00<00:00, 1167.90it/s]\n",
      "speed features: 100%|██████████| 13/13 [00:00<00:00, 198.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         k         b   k_mult  k_b  interleaved    metric        n  \\\n",
      "0     10.0      10.0      1.0  1.0         True  0.653346  2653751   \n",
      "1     10.0      10.0      1.0  1.0         True  0.653346  2653751   \n",
      "2     10.0      10.0      1.0  1.0         True  0.653346  2653751   \n",
      "3     10.0      10.0      1.0  1.0         True  0.653346  2653751   \n",
      "4     10.0      10.0      1.0  1.0         True  0.653346  2653751   \n",
      "..     ...       ...      ...  ...          ...       ...      ...   \n",
      "475  100.0  409600.0  16384.0  4.0         True  1.000000  2653751   \n",
      "476  100.0  409600.0  16384.0  4.0         True  1.000000  2653751   \n",
      "477  100.0  409600.0  16384.0  4.0         True  1.000000  2653751   \n",
      "478  100.0  409600.0  16384.0  4.0         True  1.000000  2653751   \n",
      "479  100.0  409600.0  16384.0  4.0         True  1.000000  2653751   \n",
      "\n",
      "     batch_size                                 method  duration_mean  \\\n",
      "0             1         approx_topk.torch_default.topk       0.001936   \n",
      "1            16         approx_topk.torch_default.topk       0.007826   \n",
      "2           128         approx_topk.torch_default.topk       0.052406   \n",
      "3             1  approx_topk.torch_default.bucket_topk       0.001811   \n",
      "4            16  approx_topk.torch_default.bucket_topk       0.013676   \n",
      "..          ...                                    ...            ...   \n",
      "475          16        approx_topk.priority_queue.topk       0.010556   \n",
      "476         128        approx_topk.priority_queue.topk       0.072707   \n",
      "477           1         approx_topk.torch_default.topk       0.002083   \n",
      "478          16         approx_topk.torch_default.topk       0.007824   \n",
      "479         128         approx_topk.torch_default.topk       0.052347   \n",
      "\n",
      "     duration_stdv    cost_basic   cost_serial  cost_parallel  \n",
      "0         0.000005  2.653750e+06  5.307500e+06      39.035346  \n",
      "1         0.000021  4.246000e+07  8.492000e+07      39.035346  \n",
      "2         0.000044  3.396800e+08  6.793600e+08      39.035346  \n",
      "3         0.000002  2.653750e+06  5.307500e+06      39.035346  \n",
      "4         0.000007  4.246000e+07  8.492000e+07      39.035346  \n",
      "..             ...           ...           ...            ...  \n",
      "475       0.000009  3.183439e+08  2.702060e+09    1215.318996  \n",
      "476       0.000029  2.546751e+09  2.161648e+10    1215.318996  \n",
      "477       0.000006  1.989649e+07  1.688788e+08    1215.318996  \n",
      "478       0.000020  3.183439e+08  2.702060e+09    1215.318996  \n",
      "479       0.000124  2.546751e+09  2.161648e+10    1215.318996  \n",
      "\n",
      "[480 rows x 14 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "graph_df = GraphDataFrame(\n",
    "    save_file=\"../data/graph-data-merged.csv\",\n",
    "    recall_file=\"../data/graph-recall-data.csv\", \n",
    "    speed_file=\"../data/graph-speed-data.jsonl\",\n",
    ")\n",
    "print(graph_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.4 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3031c7d28276693763c906ac6cd6e99ad46c4d38a0966ad2671ff0ba747c6d17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
